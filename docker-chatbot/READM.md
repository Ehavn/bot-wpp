## ü§ñ Microsservi√ßo Consumidor de IA para WhatsApp
Este servi√ßo √© o segundo est√°gio em um pipeline de atendimento automatizado, atuando como o "c√©rebro" do sistema. Sua fun√ß√£o √© consumir mensagens j√° processadas e enriquecidas de uma fila, gerar respostas inteligentes usando IA e envi√°-las ao usu√°rio final via WhatsApp.

## üìú Descri√ß√£o
Este projeto √© um "worker" de longa dura√ß√£o que opera de forma reativa, baseado em eventos de uma fila do RabbitMQ. O fluxo de trabalho √© o seguinte:

Escuta Ativa: O servi√ßo se conecta a uma fila espec√≠fica no RabbitMQ (ia_messages) e aguarda a chegada de "pacotes" de dados. Cada pacote cont√©m a mensagem atual do usu√°rio (j√° sanitizada) e o seu hist√≥rico de conversas. 


Leitura de Contexto: Ao receber um pacote, o bot carrega o conte√∫do de arquivos PDF locais. Esses documentos servem como uma base de conhecimento para a IA, garantindo respostas alinhadas √† regras de neg√≥cio (ex: informa√ß√µes de produtos, ap√≥lices de seguro, etc.). 


Gera√ß√£o da Resposta com IA: A pergunta do usu√°rio, o hist√≥rico da conversa e o contexto extra√≠do dos PDFs s√£o enviados ao modelo gemini-1.5-flash do Google. A IA utiliza todas essas informa√ß√µes para gerar uma resposta coesa e contextual. 


Envio via WhatsApp: A resposta gerada √© enviada para o n√∫mero de telefone do cliente atrav√©s da API oficial do WhatsApp Business. 

Este modelo garante que a l√≥gica de IA esteja completamente desacoplada dos outros sistemas, permitindo que ela seja escalada e mantida de forma independente.

## ‚ú® Funcionalidades
Arquitetura Orientada a Eventos: Consome dados de uma fila do RabbitMQ, operando em tempo real e de forma ass√≠ncrona.


Integra√ß√£o com Google Gemini: Utiliza um modelo de IA generativa para criar respostas inteligentes. 


Contexto a partir de PDFs: Enriquece o conhecimento da IA com documentos locais para fornecer respostas espec√≠ficas e precisas. 

Envio de Respostas Din√¢micas: Envia a resposta da IA para o n√∫mero de telefone correto que originou a conversa.


Pronto para Cont√™ineres: Inclui um Dockerfile otimizado para build e deploy da aplica√ß√£o. 

## üõ†Ô∏è Tecnologias Utilizadas

Python 3.11 


Pika: Para comunica√ß√£o com o RabbitMQ. 


Google Generative AI: Para a gera√ß√£o de respostas. 


PDFPlumber: Para extra√ß√£o de texto de arquivos PDF. 


Requests: Para interagir com a API do WhatsApp. 

PyMongo: Para interagir com o MongoDB (via message_dao).


Docker: Para containeriza√ß√£o. 

## ‚öôÔ∏è Configura√ß√£o
As credenciais do projeto s√£o gerenciadas pelo arquivo config/config.json.

API Key do Gemini: Obtenha sua chave de API no Google AI Studio.

WhatsApp Business: Preencha o token de acesso e o phone_number_id.

RabbitMQ: Configure o host, user, password e o nome da fila (queue).

Pasta de PDFs: Certifique-se de que o caminho em pdfs_path existe.

Exemplo do config.json:

JSON

{
  "gemini": {
    "api_key": "SUA_API_KEY_DO_GEMINI"
  },
  "whatsapp": {
    "token": "SEU_TOKEN_DE_ACESSO_WHATSAPP",
    "phone_number_id": "ID_DO_SEU_NUMERO_DE_TELEFONE"
  },
  "rabbitmq": {
    "host": "localhost",
    "user": "admin",
    "password": "admin",
    "queue": "ia_messages"
  },
  "pdfs_path": "documentos/pdfs"
}
## üöÄ Como Executar
Pr√©-requisitos:

Python 3.11 ou superior

Docker (para a op√ß√£o com cont√™iner)

Aplica√ß√£o "Preparador" em execu√ß√£o, publicando mensagens na fila ia_messages.

### 1. Execu√ß√£o Local
Bash

- 1. Clone o reposit√≥rio e acesse a pasta da aplica√ß√£o
- - ...

- 2. Crie e ative um ambiente virtual
python -m venv venv
source venv/bin/activate

- 3. Instale as depend√™ncias
pip install -r requirements.txt

- 4. Inicie o consumidor
- - (O nome do arquivo principal √© app.py)
python app.py
O terminal exibir√° a mensagem: Worker da IA iniciado. Aguardando mensagens na fila 'ia_messages'....

### 2. Execu√ß√£o com Docker
Bash

- 1. Na raiz do projeto, construa a imagem Docker
docker build -t consumidor-ia .

-  2. Execute o cont√™iner
- - A flag --network host permite que o container acesse servi√ßos (como RabbitMQ)
- - que est√£o rodando no localhost da sua m√°quina.
docker run --name meu-consumidor-ia --network host -d consumidor-ia