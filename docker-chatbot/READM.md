## ü§ñ Microsservi√ßo Consumidor de IA para WhatsApp
Este servi√ßo √© o segundo est√°gio em um pipeline de atendimento automatizado, atuando como o "c√©rebro" do sistema. Sua fun√ß√£o √© consumir mensagens j√° processadas e enriquecidas de uma fila, gerar respostas inteligentes usando IA, envi√°-las ao usu√°rio final via WhatsApp e persistir a conversa em um banco de dados.

## üìú Descri√ß√£o
Este projeto √© um "worker" de longa dura√ß√£o que opera de forma reativa, baseado em eventos de uma fila do RabbitMQ. O fluxo de trabalho √© o seguinte:

Escuta Ativa: O servi√ßo se conecta a uma fila espec√≠fica no RabbitMQ (ia_messages) e aguarda a chegada de "pacotes" de dados. Cada pacote cont√©m a mensagem atual do usu√°rio (j√° sanitizada) e o seu hist√≥rico de conversas.

Leitura de Contexto: Ao receber um pacote, o bot carrega o conte√∫do de arquivos PDF locais. Esses documentos servem como uma base de conhecimento para a IA, garantindo respostas alinhadas √† regras de neg√≥cio (ex: informa√ß√µes de produtos, ap√≥lices de seguro, etc.).

Gera√ß√£o da Resposta com IA: A pergunta do usu√°rio, o hist√≥rico da conversa e o contexto extra√≠do dos PDFs s√£o enviados ao modelo gemini-1.5-flash do Google. A IA utiliza todas essas informa√ß√µes para gerar uma resposta coesa e contextual.

Envio via WhatsApp: A resposta gerada √© enviada para o n√∫mero de telefone do cliente atrav√©s da API oficial do WhatsApp Business.

## Persist√™ncia da Conversa: Ap√≥s o envio, a resposta da IA √© salva no MongoDB, garantindo que o hist√≥rico da conversa esteja sempre completo e atualizado para futuras intera√ß√µes.

Este modelo garante que a l√≥gica de IA esteja completamente desacoplada dos outros sistemas, permitindo que ela seja escalada e mantida de forma independente.

## ‚ú® Funcionalidades
Arquitetura Orientada a Eventos: Consome dados de uma fila do RabbitMQ, operando em tempo real e de forma ass√≠ncrona.

Integra√ß√£o com Google Gemini: Utiliza um modelo de IA generativa para criar respostas inteligentes.

Contexto a partir de PDFs: Enriquece o conhecimento da IA com documentos locais para fornecer respostas espec√≠ficas e precisas.

Envio de Respostas Din√¢micas: Envia a resposta da IA para o n√∫mero de telefone correto que originou a conversa.

## Persist√™ncia de Conversas: Salva as respostas geradas pela IA no MongoDB, criando um hist√≥rico completo do di√°logo.

Pronto para Cont√™ineres: Inclui um Dockerfile otimizado para build e deploy da aplica√ß√£o.

## üõ†Ô∏è Tecnologias Utilizadas
Python 3.11

Pika: Para comunica√ß√£o com o RabbitMQ.

Google Generative AI: Para a gera√ß√£o de respostas.

PDFPlumber: Para extra√ß√£o de texto de arquivos PDF.

Requests: Para interagir com a API do WhatsApp.

PyMongo: Para interagir com o MongoDB (via message_dao).

Docker: Para containeriza√ß√£o.

## ‚öôÔ∏è Configura√ß√£o (‚úèÔ∏è ATUALIZADO)
As credenciais do projeto s√£o gerenciadas pelo arquivo config/config.json.

API Key do Gemini: Obtenha sua chave de API no Google AI Studio.

WhatsApp Business: Preencha o token de acesso e o phone_number_id.

RabbitMQ: Configure o host, user, password e o nome da queue.

MongoDB: Adicione a connectionUri do seu cluster, o db_name e o collection_messages.

Pasta de PDFs: Certifique-se de que o caminho em pdfs_path existe.

Exemplo do config.json:

JSON

{
  "gemini": {
    "api_key": "SUA_API_KEY_DO_GEMINI"
  },
  "whatsapp": {
    "token": "SEU_TOKEN_DE_ACESSO_WHATSAPP",
    "phone_number_id": "ID_DO_SEU_NUMERO_DE_TELEFONE"
  },
  "rabbitmq": {
    "host": "localhost",
    "user": "admin",
    "password": "admin",
    "queue": "ia_messages"
  },
  "mongo": {
    "connectionUri": "mongodb+srv://<user>:<password>@<cluster-url>/<db-name>?retryWrites=true&w=majority",
    "db_name": "chatbot_db",
    "collection_messages": "messages"
  },
  "pdfs_path": "documents/pdfs"
}
## üöÄ Como Executar
Pr√©-requisitos:

Python 3.11 ou superior

Docker (para a op√ß√£o com cont√™iner)

Aplica√ß√£o "Preparador" em execu√ß√£o, publicando mensagens na fila ia_messages.

## ‚ú® Acesso a um cluster MongoDB com as credenciais corretas.

### 1. Execu√ß√£o Local
Bash

- 1. Clone o reposit√≥rio e acesse a pasta da aplica√ß√£o
- - ...

- 2. Crie e ative um ambiente virtual
python -m venv venv
source venv/bin/activate  # No Windows: venv\Scripts\activate

- 3. Instale as depend√™ncias
pip install -r requirements.txt

- 4. Inicie o consumidor
- - (O nome do arquivo principal √© app.py)
python app.py
O terminal exibir√° a mensagem: Worker da IA iniciado. Aguardando mensagens na fila 'ia_messages'....

### 2. Execu√ß√£o com Docker
Bash

- 1. Na raiz do projeto, construa a imagem Docker
docker build -t consumidor-ia .

- 2. Execute o cont√™iner
- - A flag --network host permite que o container acesse servi√ßos (como RabbitMQ e MongoDB)
- - que est√£o rodando no localhost da sua m√°quina.
docker run --name meu-consumidor-ia --network host -d consumidor-ia